{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Keys Optimizer\n",
    "\n",
    "Here we create the custom keys dictionary for the runner config.\n",
    "It is necessary to get layer decay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAYER_DECAY = 0.75\n",
    "MODEL_DEPTH = 12\n",
    "BASE_WEIGHT_DECAY = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/04 22:32:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: darwin\n",
      "    Python: 3.10.13 | packaged by conda-forge | (main, Oct 26 2023, 18:09:17) [Clang 16.0.6 ]\n",
      "    CUDA available: False\n",
      "    numpy_random_seed: 104644062\n",
      "    GCC: Apple clang version 15.0.0 (clang-1500.0.40.1)\n",
      "    PyTorch: 2.1.1\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 4.2\n",
      "  - C++ Version: 201703\n",
      "  - clang 13.1.6\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: NO AVX\n",
      "  - Build settings: BLAS_INFO=accelerate, BUILD_TYPE=Release, CXX_COMPILER=/Applications/Xcode_13.3.1.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/clang++, CXX_FLAGS= -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_PYTORCH_METAL_EXPORT -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DUSE_COREML_DELEGATE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=braced-scalar-init -Werror=range-loop-construct -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wvla-extension -Wnewline-eof -Winconsistent-missing-override -Winconsistent-missing-destructor-override -Wno-range-loop-analysis -Wno-pass-failed -Wsuggest-override -Wno-error=pedantic -Wno-error=old-style-cast -Wno-error=inconsistent-missing-override -Wno-error=inconsistent-missing-destructor-override -Wconstant-conversion -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-missing-braces -Wunused-lambda-capture -Qunused-arguments -fcolor-diagnostics -faligned-new -Wno-unused-but-set-variable -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -DUSE_MPS -Wno-unused-private-field -Wno-missing-braces, LAPACK_INFO=accelerate, TORCH_DISABLE_GPU_ASSERTS=OFF, TORCH_VERSION=2.1.1, USE_CUDA=0, USE_CUDNN=OFF, USE_EIGEN_FOR_BLAS=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=OFF, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=ON, USE_OPENMP=OFF, USE_ROCM=OFF, \n",
      "\n",
      "    TorchVision: 0.16.1\n",
      "    OpenCV: 4.8.1\n",
      "    MMEngine: 0.10.1\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: False\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    seed: 104644062\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "12/04 22:32:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
      "ann_file_test = 'data/Fall_Simulation_Data/annotations_test.csv'\n",
      "ann_file_train = 'data/Fall_Simulation_Data/annotations_train.csv'\n",
      "ann_file_val = 'data/Fall_Simulation_Data/annotations_val.csv'\n",
      "custom_hooks = [\n",
      "    dict(enable=True, type='CustomVisualizationHook'),\n",
      "]\n",
      "custom_imports = dict(\n",
      "    allow_failed_imports=False,\n",
      "    imports=[\n",
      "        'datasets',\n",
      "        'evaluation',\n",
      "        'visualization',\n",
      "    ])\n",
      "dataset_type = 'HighQualityFallDataset'\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(\n",
      "        by_epoch=True,\n",
      "        interval=3,\n",
      "        max_keep_ckpts=3,\n",
      "        save_best='auto',\n",
      "        type='CheckpointHook'),\n",
      "    logger=dict(type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    runtime_info=dict(type='RuntimeInfoHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    sync_buffers=dict(type='SyncBuffersHook'),\n",
      "    timer=dict(type='IterTimerHook'))\n",
      "default_scope = 'mmaction'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=False,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "label_strategy = dict(\n",
      "    label_description=dict(\n",
      "        end_timestamp_names=[\n",
      "            'fall_end',\n",
      "            'lying_end',\n",
      "        ],\n",
      "        names=[\n",
      "            'fall',\n",
      "            'lying',\n",
      "            'other',\n",
      "        ],\n",
      "        other_class=2,\n",
      "        start_timestamp_names=[\n",
      "            'fall_start',\n",
      "            'lying_start',\n",
      "        ],\n",
      "        visible_names=[\n",
      "            'fall_visible',\n",
      "            'lying_visible',\n",
      "        ]),\n",
      "    type='PriorityLabel')\n",
      "launcher = 'none'\n",
      "load_from = 'weights/vit-small-p16_videomaev2-vit-g-dist-k710-pre_16x4x1_kinetics-400_20230510-25c748fd.pth'\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=10)\n",
      "model = dict(\n",
      "    backbone=dict(\n",
      "        depth=12,\n",
      "        drop_path_rate=0.3,\n",
      "        embed_dims=384,\n",
      "        img_size=224,\n",
      "        mlp_ratio=4,\n",
      "        norm_cfg=dict(eps=1e-06, type='LN'),\n",
      "        num_frames=16,\n",
      "        num_heads=6,\n",
      "        patch_size=16,\n",
      "        qkv_bias=True,\n",
      "        type='VisionTransformer'),\n",
      "    cls_head=dict(\n",
      "        average_clips='prob',\n",
      "        in_channels=384,\n",
      "        num_classes=3,\n",
      "        topk=(1, ),\n",
      "        type='TimeSformerHead'),\n",
      "    data_preprocessor=dict(\n",
      "        format_shape='NCTHW',\n",
      "        mean=[\n",
      "            102.17311096191406,\n",
      "            98.78225708007812,\n",
      "            92.68714141845703,\n",
      "        ],\n",
      "        std=[\n",
      "            58.04566192626953,\n",
      "            57.004024505615234,\n",
      "            57.3704948425293,\n",
      "        ],\n",
      "        type='ActionDataPreprocessor'),\n",
      "    type='Recognizer3D')\n",
      "optim_wrapper = dict(\n",
      "    clip_grad=dict(max_norm=5, norm_type=2),\n",
      "    optimizer=dict(\n",
      "        betas=(\n",
      "            0.9,\n",
      "            0.999,\n",
      "        ), lr=0.001, type='AdamW', weight_decay=0.1),\n",
      "    type='AmpOptimWrapper')\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        begin=0,\n",
      "        by_epoch=True,\n",
      "        convert_to_iter_based=True,\n",
      "        end=5,\n",
      "        end_factor=1,\n",
      "        start_factor=0.001,\n",
      "        type='LinearLR'),\n",
      "    dict(\n",
      "        begin=5,\n",
      "        by_epoch=True,\n",
      "        convert_to_iter_based=True,\n",
      "        end=35,\n",
      "        eta_min=1e-06,\n",
      "        type='CosineAnnealingLR'),\n",
      "]\n",
      "resume = False\n",
      "sampling_strategy = dict(clip_len=10, type='UniformSampling')\n",
      "test_cfg = dict(type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=3,\n",
      "    dataset=dict(\n",
      "        ann_file='data/Fall_Simulation_Data/annotations_test.csv',\n",
      "        label_strategy=dict(\n",
      "            label_description=dict(\n",
      "                end_timestamp_names=[\n",
      "                    'fall_end',\n",
      "                    'lying_end',\n",
      "                ],\n",
      "                names=[\n",
      "                    'fall',\n",
      "                    'lying',\n",
      "                    'other',\n",
      "                ],\n",
      "                other_class=2,\n",
      "                start_timestamp_names=[\n",
      "                    'fall_start',\n",
      "                    'lying_start',\n",
      "                ],\n",
      "                visible_names=[\n",
      "                    'fall_visible',\n",
      "                    'lying_visible',\n",
      "                ]),\n",
      "            type='PriorityLabel'),\n",
      "        num_classes=3,\n",
      "        pipeline=[\n",
      "            dict(type='DecordInit'),\n",
      "            dict(\n",
      "                clip_len=16,\n",
      "                frame_interval=4,\n",
      "                num_clips=5,\n",
      "                test_mode=True,\n",
      "                type='SampleFrames'),\n",
      "            dict(type='DecordDecode'),\n",
      "            dict(scale=(\n",
      "                -1,\n",
      "                224,\n",
      "            ), type='Resize'),\n",
      "            dict(crop_size=224, type='ThreeCrop'),\n",
      "            dict(input_format='NCTHW', type='FormatShape'),\n",
      "            dict(type='PackActionInputs'),\n",
      "        ],\n",
      "        sampling_strategy=dict(clip_len=10, type='UniformSampling'),\n",
      "        type='HighQualityFallDataset'),\n",
      "    num_workers=8,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = dict(\n",
      "    metric_list=(\n",
      "        'unweighted_average_f1',\n",
      "        'per_class_f1',\n",
      "        'per_class_precision',\n",
      "        'per_class_recall',\n",
      "    ),\n",
      "    type='AddAccMetric')\n",
      "test_pipeline = [\n",
      "    dict(type='DecordInit'),\n",
      "    dict(\n",
      "        clip_len=16,\n",
      "        frame_interval=4,\n",
      "        num_clips=5,\n",
      "        test_mode=True,\n",
      "        type='SampleFrames'),\n",
      "    dict(type='DecordDecode'),\n",
      "    dict(scale=(\n",
      "        -1,\n",
      "        224,\n",
      "    ), type='Resize'),\n",
      "    dict(crop_size=224, type='ThreeCrop'),\n",
      "    dict(input_format='NCTHW', type='FormatShape'),\n",
      "    dict(type='PackActionInputs'),\n",
      "]\n",
      "train_cfg = dict(max_epochs=35, type='EpochBasedTrainLoop', val_interval=1)\n",
      "train_dataloader = dict(\n",
      "    batch_size=3,\n",
      "    dataset=dict(\n",
      "        ann_file='data/Fall_Simulation_Data/annotations_train.csv',\n",
      "        label_strategy=dict(\n",
      "            label_description=dict(\n",
      "                end_timestamp_names=[\n",
      "                    'fall_end',\n",
      "                    'lying_end',\n",
      "                ],\n",
      "                names=[\n",
      "                    'fall',\n",
      "                    'lying',\n",
      "                    'other',\n",
      "                ],\n",
      "                other_class=2,\n",
      "                start_timestamp_names=[\n",
      "                    'fall_start',\n",
      "                    'lying_start',\n",
      "                ],\n",
      "                visible_names=[\n",
      "                    'fall_visible',\n",
      "                    'lying_visible',\n",
      "                ]),\n",
      "            type='PriorityLabel'),\n",
      "        num_classes=3,\n",
      "        pipeline=[\n",
      "            dict(type='DecordInit'),\n",
      "            dict(type='ClipVideo'),\n",
      "            dict(\n",
      "                clip_len=16,\n",
      "                frame_interval=4,\n",
      "                num_clips=1,\n",
      "                type='SampleFrames'),\n",
      "            dict(type='DecordDecode'),\n",
      "            dict(scale=(\n",
      "                -1,\n",
      "                224,\n",
      "            ), type='Resize'),\n",
      "            dict(size=224, type='RandomCrop'),\n",
      "            dict(keep_ratio=False, scale=(\n",
      "                224,\n",
      "                224,\n",
      "            ), type='Resize'),\n",
      "            dict(flip_ratio=0.5, type='Flip'),\n",
      "            dict(input_format='NCTHW', type='FormatShape'),\n",
      "            dict(type='PackActionInputs'),\n",
      "        ],\n",
      "        sampling_strategy=dict(clip_len=10, type='UniformSampling'),\n",
      "        type='HighQualityFallDataset'),\n",
      "    num_workers=8,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
      "train_pipeline = [\n",
      "    dict(type='DecordInit'),\n",
      "    dict(type='ClipVideo'),\n",
      "    dict(clip_len=16, frame_interval=4, num_clips=1, type='SampleFrames'),\n",
      "    dict(type='DecordDecode'),\n",
      "    dict(scale=(\n",
      "        -1,\n",
      "        224,\n",
      "    ), type='Resize'),\n",
      "    dict(size=224, type='RandomCrop'),\n",
      "    dict(keep_ratio=False, scale=(\n",
      "        224,\n",
      "        224,\n",
      "    ), type='Resize'),\n",
      "    dict(flip_ratio=0.5, type='Flip'),\n",
      "    dict(input_format='NCTHW', type='FormatShape'),\n",
      "    dict(type='PackActionInputs'),\n",
      "]\n",
      "val_cfg = dict(type='ValLoop')\n",
      "val_dataloader = dict(\n",
      "    batch_size=3,\n",
      "    dataset=dict(\n",
      "        ann_file='data/Fall_Simulation_Data/annotations_val.csv',\n",
      "        label_strategy=dict(\n",
      "            label_description=dict(\n",
      "                end_timestamp_names=[\n",
      "                    'fall_end',\n",
      "                    'lying_end',\n",
      "                ],\n",
      "                names=[\n",
      "                    'fall',\n",
      "                    'lying',\n",
      "                    'other',\n",
      "                ],\n",
      "                other_class=2,\n",
      "                start_timestamp_names=[\n",
      "                    'fall_start',\n",
      "                    'lying_start',\n",
      "                ],\n",
      "                visible_names=[\n",
      "                    'fall_visible',\n",
      "                    'lying_visible',\n",
      "                ]),\n",
      "            type='PriorityLabel'),\n",
      "        num_classes=3,\n",
      "        pipeline=[\n",
      "            dict(type='DecordInit'),\n",
      "            dict(type='ClipVideo'),\n",
      "            dict(\n",
      "                clip_len=16,\n",
      "                frame_interval=4,\n",
      "                num_clips=1,\n",
      "                test_mode=True,\n",
      "                type='SampleFrames'),\n",
      "            dict(type='DecordDecode'),\n",
      "            dict(scale=(\n",
      "                -1,\n",
      "                224,\n",
      "            ), type='Resize'),\n",
      "            dict(crop_size=224, type='CenterCrop'),\n",
      "            dict(input_format='NCTHW', type='FormatShape'),\n",
      "            dict(type='PackActionInputs'),\n",
      "        ],\n",
      "        sampling_strategy=dict(clip_len=10, type='UniformSampling'),\n",
      "        type='HighQualityFallDataset'),\n",
      "    num_workers=8,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = dict(\n",
      "    metric_list=(\n",
      "        'unweighted_average_f1',\n",
      "        'per_class_f1',\n",
      "        'per_class_precision',\n",
      "        'per_class_recall',\n",
      "    ),\n",
      "    type='AddAccMetric')\n",
      "val_pipeline = [\n",
      "    dict(type='DecordInit'),\n",
      "    dict(type='ClipVideo'),\n",
      "    dict(\n",
      "        clip_len=16,\n",
      "        frame_interval=4,\n",
      "        num_clips=1,\n",
      "        test_mode=True,\n",
      "        type='SampleFrames'),\n",
      "    dict(type='DecordDecode'),\n",
      "    dict(scale=(\n",
      "        -1,\n",
      "        224,\n",
      "    ), type='Resize'),\n",
      "    dict(crop_size=224, type='CenterCrop'),\n",
      "    dict(input_format='NCTHW', type='FormatShape'),\n",
      "    dict(type='PackActionInputs'),\n",
      "]\n",
      "vis_backends = dict(\n",
      "    save_dir='experiments/tensorboard', type='TensorboardVisBackend')\n",
      "visualizer = dict(\n",
      "    type='ActionVisualizer',\n",
      "    vis_backends=dict(\n",
      "        save_dir='experiments/tensorboard', type='TensorboardVisBackend'))\n",
      "work_dir = 'experiments'\n",
      "\n",
      "12/04 22:32:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "12/04 22:32:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SyncBuffersHook                    \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SyncBuffersHook                    \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) CustomVisualizationHook            \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) CustomVisualizationHook            \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n"
     ]
    }
   ],
   "source": [
    "from mmengine.runner import Runner\n",
    "from mmengine.config import Config\n",
    "\n",
    "runner_cfg = Config.fromfile(\n",
    "    \"configs/models/vit-s-p16_videomaev2-vit-g-dist-k710-pre_16x4x1_kinetics-400_base.py\"\n",
    ")\n",
    "runner = Runner.from_cfg(runner_cfg)\n",
    "model = runner.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions from the VideoMAE repo\n",
    "\n",
    "\n",
    "def get_num_layer_for_vit(var_name, num_max_layer):\n",
    "    if var_name in (\"backbone.cls_token\", \"backbone.mask_token\", \"backbone.pos_embed\"):\n",
    "        return 0\n",
    "    elif var_name.startswith(\"backbone.patch_embed\"):\n",
    "        return 0\n",
    "    elif var_name.startswith(\"backbone.rel_pos_bias\"):\n",
    "        return num_max_layer - 1\n",
    "    elif var_name.startswith(\"backbone.blocks\"):\n",
    "        layer_id = int(var_name.split(\".\")[2])\n",
    "        return layer_id + 1\n",
    "    else:\n",
    "        return num_max_layer - 1\n",
    "\n",
    "\n",
    "class LayerDecayValueAssigner(object):\n",
    "    def __init__(self, values):\n",
    "        self.values = values\n",
    "\n",
    "    def get_scale(self, layer_id):\n",
    "        return self.values[layer_id]\n",
    "\n",
    "    def get_layer_id(self, var_name):\n",
    "        return get_num_layer_for_vit(var_name, len(self.values))\n",
    "\n",
    "\n",
    "def get_parameter_groups(\n",
    "    model, weight_decay=1e-5, skip_list=(), get_num_layer=None, get_layer_scale=None\n",
    "):\n",
    "    parameter_group_names = {}\n",
    "    parameter_group_vars = {}\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        if not param.requires_grad:\n",
    "            continue  # frozen weights\n",
    "        if (\n",
    "            len(param.shape) == 1\n",
    "            or name.endswith(\".bias\")\n",
    "            or name.endswith(\".scale\")\n",
    "            or name in skip_list\n",
    "        ):\n",
    "            group_name = \"no_decay\"\n",
    "            this_weight_decay = 0.0\n",
    "        else:\n",
    "            group_name = \"decay\"\n",
    "            this_weight_decay = weight_decay\n",
    "        if get_num_layer is not None:\n",
    "            layer_id = get_num_layer(name)\n",
    "            group_name = \"layer_%d_%s\" % (layer_id, group_name)\n",
    "        else:\n",
    "            layer_id = None\n",
    "\n",
    "        if group_name not in parameter_group_names:\n",
    "            if get_layer_scale is not None:\n",
    "                scale = get_layer_scale(layer_id)\n",
    "            else:\n",
    "                scale = 1.0\n",
    "\n",
    "            parameter_group_names[group_name] = {\n",
    "                \"weight_decay\": this_weight_decay,\n",
    "                \"params\": [],\n",
    "                \"lr_scale\": scale,\n",
    "            }\n",
    "            parameter_group_vars[group_name] = {\n",
    "                \"weight_decay\": this_weight_decay,\n",
    "                \"params\": [],\n",
    "                \"lr_scale\": scale,\n",
    "            }\n",
    "\n",
    "        parameter_group_vars[group_name][\"params\"].append(param)\n",
    "        parameter_group_names[group_name][\"params\"].append(name)\n",
    "\n",
    "    return parameter_group_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the parameter groups from VideoMAE\n",
    "\n",
    "assigner = LayerDecayValueAssigner(\n",
    "    list(LAYER_DECAY ** (MODEL_DEPTH + 1 - i) for i in range(MODEL_DEPTH + 2))\n",
    ")\n",
    "\n",
    "groups = get_parameter_groups(\n",
    "    model,\n",
    "    BASE_WEIGHT_DECAY,\n",
    "    get_num_layer=assigner.get_layer_id,\n",
    "    get_layer_scale=assigner.get_scale,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'backbone.patch_embed.projection.weight': {'lr_mult': 0.023757264018058777,\n",
       "  'decay_mult': 1},\n",
       " 'backbone.patch_embed.projection.bias': {'lr_mult': 0.023757264018058777,\n",
       "  'decay_mult': 0},\n",
       " 'backbone.blocks.0.norm1.weight': {'lr_mult': 0.03167635202407837,\n",
       "  'decay_mult': 0},\n",
       " 'backbone.blocks.0.norm1.bias': {'lr_mult': 0.03167635202407837,\n",
       "  'decay_mult': 0},\n",
       " 'backbone.blocks.0.attn.q_bias': {'lr_mult': 0.03167635202407837,\n",
       "  'decay_mult': 0},\n",
       " 'backbone.blocks.0.attn.v_bias': {'lr_mult': 0.03167635202407837,\n",
       "  'decay_mult': 0},\n",
       " 'backbone.blocks.0.attn.proj.bias': {'lr_mult': 0.03167635202407837,\n",
       "  'decay_mult': 0},\n",
       " 'backbone.blocks.0.norm2.weight': {'lr_mult': 0.03167635202407837,\n",
       "  'decay_mult': 0},\n",
       " 'backbone.blocks.0.norm2.bias': {'lr_mult': 0.03167635202407837,\n",
       "  'decay_mult': 0},\n",
       " 'backbone.blocks.0.mlp.layers.0.0.bias': {'lr_mult': 0.03167635202407837,\n",
       "  'decay_mult': 0},\n",
       " 'backbone.blocks.0.mlp.layers.1.bias': {'lr_mult': 0.03167635202407837,\n",
       "  'decay_mult': 0},\n",
       " 'backbone.blocks.0.attn.qkv.weight': {'lr_mult': 0.03167635202407837,\n",
       "  'decay_mult': 1},\n",
       " 'backbone.blocks.0.attn.proj.weight': {'lr_mult': 0.03167635202407837,\n",
       "  'decay_mult': 1},\n",
       " 'backbone.blocks.0.mlp.layers.0.0.weight': {'lr_mult': 0.03167635202407837,\n",
       "  'decay_mult': 1},\n",
       " 'backbone.blocks.0.mlp.layers.1.weight': {'lr_mult': 0.03167635202407837,\n",
       "  'decay_mult': 1},\n",
       " 'backbone.blocks.1.norm1.weight': {'lr_mult': 0.04223513603210449,\n",
       "  'decay_mult': 0},\n",
       " 'backbone.blocks.1.norm1.bias': {'lr_mult': 0.04223513603210449,\n",
       "  'decay_mult': 0},\n",
       " 'backbone.blocks.1.attn.q_bias': {'lr_mult': 0.04223513603210449,\n",
       "  'decay_mult': 0},\n",
       " 'backbone.blocks.1.attn.v_bias': {'lr_mult': 0.04223513603210449,\n",
       "  'decay_mult': 0},\n",
       " 'backbone.blocks.1.attn.proj.bias': {'lr_mult': 0.04223513603210449,\n",
       "  'decay_mult': 0},\n",
       " 'backbone.blocks.1.norm2.weight': {'lr_mult': 0.04223513603210449,\n",
       "  'decay_mult': 0},\n",
       " 'backbone.blocks.1.norm2.bias': {'lr_mult': 0.04223513603210449,\n",
       "  'decay_mult': 0},\n",
       " 'backbone.blocks.1.mlp.layers.0.0.bias': {'lr_mult': 0.04223513603210449,\n",
       "  'decay_mult': 0},\n",
       " 'backbone.blocks.1.mlp.layers.1.bias': {'lr_mult': 0.04223513603210449,\n",
       "  'decay_mult': 0},\n",
       " 'backbone.blocks.1.attn.qkv.weight': {'lr_mult': 0.04223513603210449,\n",
       "  'decay_mult': 1},\n",
       " 'backbone.blocks.1.attn.proj.weight': {'lr_mult': 0.04223513603210449,\n",
       "  'decay_mult': 1},\n",
       " 'backbone.blocks.1.mlp.layers.0.0.weight': {'lr_mult': 0.04223513603210449,\n",
       "  'decay_mult': 1},\n",
       " 'backbone.blocks.1.mlp.layers.1.weight': {'lr_mult': 0.04223513603210449,\n",
       "  'decay_mult': 1},\n",
       " 'backbone.blocks.2.norm1.weight': {'lr_mult': 0.056313514709472656,\n",
       "  'decay_mult': 0},\n",
       " 'backbone.blocks.2.norm1.bias': {'lr_mult': 0.056313514709472656,\n",
       "  'decay_mult': 0},\n",
       " 'backbone.blocks.2.attn.q_bias': {'lr_mult': 0.056313514709472656,\n",
       "  'decay_mult': 0},\n",
       " 'backbone.blocks.2.attn.v_bias': {'lr_mult': 0.056313514709472656,\n",
       "  'decay_mult': 0},\n",
       " 'backbone.blocks.2.attn.proj.bias': {'lr_mult': 0.056313514709472656,\n",
       "  'decay_mult': 0},\n",
       " 'backbone.blocks.2.norm2.weight': {'lr_mult': 0.056313514709472656,\n",
       "  'decay_mult': 0},\n",
       " 'backbone.blocks.2.norm2.bias': {'lr_mult': 0.056313514709472656,\n",
       "  'decay_mult': 0},\n",
       " 'backbone.blocks.2.mlp.layers.0.0.bias': {'lr_mult': 0.056313514709472656,\n",
       "  'decay_mult': 0},\n",
       " 'backbone.blocks.2.mlp.layers.1.bias': {'lr_mult': 0.056313514709472656,\n",
       "  'decay_mult': 0},\n",
       " 'backbone.blocks.2.attn.qkv.weight': {'lr_mult': 0.056313514709472656,\n",
       "  'decay_mult': 1},\n",
       " 'backbone.blocks.2.attn.proj.weight': {'lr_mult': 0.056313514709472656,\n",
       "  'decay_mult': 1},\n",
       " 'backbone.blocks.2.mlp.layers.0.0.weight': {'lr_mult': 0.056313514709472656,\n",
       "  'decay_mult': 1},\n",
       " 'backbone.blocks.2.mlp.layers.1.weight': {'lr_mult': 0.056313514709472656,\n",
       "  'decay_mult': 1},\n",
       " 'backbone.blocks.3.norm1.weight': {'lr_mult': 0.07508468627929688,\n",
       "  'decay_mult': 0},\n",
       " 'backbone.blocks.3.norm1.bias': {'lr_mult': 0.07508468627929688,\n",
       "  'decay_mult': 0},\n",
       " 'backbone.blocks.3.attn.q_bias': {'lr_mult': 0.07508468627929688,\n",
       "  'decay_mult': 0},\n",
       " 'backbone.blocks.3.attn.v_bias': {'lr_mult': 0.07508468627929688,\n",
       "  'decay_mult': 0},\n",
       " 'backbone.blocks.3.attn.proj.bias': {'lr_mult': 0.07508468627929688,\n",
       "  'decay_mult': 0},\n",
       " 'backbone.blocks.3.norm2.weight': {'lr_mult': 0.07508468627929688,\n",
       "  'decay_mult': 0},\n",
       " 'backbone.blocks.3.norm2.bias': {'lr_mult': 0.07508468627929688,\n",
       "  'decay_mult': 0},\n",
       " 'backbone.blocks.3.mlp.layers.0.0.bias': {'lr_mult': 0.07508468627929688,\n",
       "  'decay_mult': 0},\n",
       " 'backbone.blocks.3.mlp.layers.1.bias': {'lr_mult': 0.07508468627929688,\n",
       "  'decay_mult': 0},\n",
       " 'backbone.blocks.3.attn.qkv.weight': {'lr_mult': 0.07508468627929688,\n",
       "  'decay_mult': 1},\n",
       " 'backbone.blocks.3.attn.proj.weight': {'lr_mult': 0.07508468627929688,\n",
       "  'decay_mult': 1},\n",
       " 'backbone.blocks.3.mlp.layers.0.0.weight': {'lr_mult': 0.07508468627929688,\n",
       "  'decay_mult': 1},\n",
       " 'backbone.blocks.3.mlp.layers.1.weight': {'lr_mult': 0.07508468627929688,\n",
       "  'decay_mult': 1},\n",
       " 'backbone.blocks.4.norm1.weight': {'lr_mult': 0.1001129150390625,\n",
       "  'decay_mult': 0},\n",
       " 'backbone.blocks.4.norm1.bias': {'lr_mult': 0.1001129150390625,\n",
       "  'decay_mult': 0},\n",
       " 'backbone.blocks.4.attn.q_bias': {'lr_mult': 0.1001129150390625,\n",
       "  'decay_mult': 0},\n",
       " 'backbone.blocks.4.attn.v_bias': {'lr_mult': 0.1001129150390625,\n",
       "  'decay_mult': 0},\n",
       " 'backbone.blocks.4.attn.proj.bias': {'lr_mult': 0.1001129150390625,\n",
       "  'decay_mult': 0},\n",
       " 'backbone.blocks.4.norm2.weight': {'lr_mult': 0.1001129150390625,\n",
       "  'decay_mult': 0},\n",
       " 'backbone.blocks.4.norm2.bias': {'lr_mult': 0.1001129150390625,\n",
       "  'decay_mult': 0},\n",
       " 'backbone.blocks.4.mlp.layers.0.0.bias': {'lr_mult': 0.1001129150390625,\n",
       "  'decay_mult': 0},\n",
       " 'backbone.blocks.4.mlp.layers.1.bias': {'lr_mult': 0.1001129150390625,\n",
       "  'decay_mult': 0},\n",
       " 'backbone.blocks.4.attn.qkv.weight': {'lr_mult': 0.1001129150390625,\n",
       "  'decay_mult': 1},\n",
       " 'backbone.blocks.4.attn.proj.weight': {'lr_mult': 0.1001129150390625,\n",
       "  'decay_mult': 1},\n",
       " 'backbone.blocks.4.mlp.layers.0.0.weight': {'lr_mult': 0.1001129150390625,\n",
       "  'decay_mult': 1},\n",
       " 'backbone.blocks.4.mlp.layers.1.weight': {'lr_mult': 0.1001129150390625,\n",
       "  'decay_mult': 1},\n",
       " 'backbone.blocks.5.norm1.weight': {'lr_mult': 0.13348388671875,\n",
       "  'decay_mult': 0},\n",
       " 'backbone.blocks.5.norm1.bias': {'lr_mult': 0.13348388671875,\n",
       "  'decay_mult': 0},\n",
       " 'backbone.blocks.5.attn.q_bias': {'lr_mult': 0.13348388671875,\n",
       "  'decay_mult': 0},\n",
       " 'backbone.blocks.5.attn.v_bias': {'lr_mult': 0.13348388671875,\n",
       "  'decay_mult': 0},\n",
       " 'backbone.blocks.5.attn.proj.bias': {'lr_mult': 0.13348388671875,\n",
       "  'decay_mult': 0},\n",
       " 'backbone.blocks.5.norm2.weight': {'lr_mult': 0.13348388671875,\n",
       "  'decay_mult': 0},\n",
       " 'backbone.blocks.5.norm2.bias': {'lr_mult': 0.13348388671875,\n",
       "  'decay_mult': 0},\n",
       " 'backbone.blocks.5.mlp.layers.0.0.bias': {'lr_mult': 0.13348388671875,\n",
       "  'decay_mult': 0},\n",
       " 'backbone.blocks.5.mlp.layers.1.bias': {'lr_mult': 0.13348388671875,\n",
       "  'decay_mult': 0},\n",
       " 'backbone.blocks.5.attn.qkv.weight': {'lr_mult': 0.13348388671875,\n",
       "  'decay_mult': 1},\n",
       " 'backbone.blocks.5.attn.proj.weight': {'lr_mult': 0.13348388671875,\n",
       "  'decay_mult': 1},\n",
       " 'backbone.blocks.5.mlp.layers.0.0.weight': {'lr_mult': 0.13348388671875,\n",
       "  'decay_mult': 1},\n",
       " 'backbone.blocks.5.mlp.layers.1.weight': {'lr_mult': 0.13348388671875,\n",
       "  'decay_mult': 1},\n",
       " 'backbone.blocks.6.norm1.weight': {'lr_mult': 0.177978515625,\n",
       "  'decay_mult': 0},\n",
       " 'backbone.blocks.6.norm1.bias': {'lr_mult': 0.177978515625, 'decay_mult': 0},\n",
       " 'backbone.blocks.6.attn.q_bias': {'lr_mult': 0.177978515625, 'decay_mult': 0},\n",
       " 'backbone.blocks.6.attn.v_bias': {'lr_mult': 0.177978515625, 'decay_mult': 0},\n",
       " 'backbone.blocks.6.attn.proj.bias': {'lr_mult': 0.177978515625,\n",
       "  'decay_mult': 0},\n",
       " 'backbone.blocks.6.norm2.weight': {'lr_mult': 0.177978515625,\n",
       "  'decay_mult': 0},\n",
       " 'backbone.blocks.6.norm2.bias': {'lr_mult': 0.177978515625, 'decay_mult': 0},\n",
       " 'backbone.blocks.6.mlp.layers.0.0.bias': {'lr_mult': 0.177978515625,\n",
       "  'decay_mult': 0},\n",
       " 'backbone.blocks.6.mlp.layers.1.bias': {'lr_mult': 0.177978515625,\n",
       "  'decay_mult': 0},\n",
       " 'backbone.blocks.6.attn.qkv.weight': {'lr_mult': 0.177978515625,\n",
       "  'decay_mult': 1},\n",
       " 'backbone.blocks.6.attn.proj.weight': {'lr_mult': 0.177978515625,\n",
       "  'decay_mult': 1},\n",
       " 'backbone.blocks.6.mlp.layers.0.0.weight': {'lr_mult': 0.177978515625,\n",
       "  'decay_mult': 1},\n",
       " 'backbone.blocks.6.mlp.layers.1.weight': {'lr_mult': 0.177978515625,\n",
       "  'decay_mult': 1},\n",
       " 'backbone.blocks.7.norm1.weight': {'lr_mult': 0.2373046875, 'decay_mult': 0},\n",
       " 'backbone.blocks.7.norm1.bias': {'lr_mult': 0.2373046875, 'decay_mult': 0},\n",
       " 'backbone.blocks.7.attn.q_bias': {'lr_mult': 0.2373046875, 'decay_mult': 0},\n",
       " 'backbone.blocks.7.attn.v_bias': {'lr_mult': 0.2373046875, 'decay_mult': 0},\n",
       " 'backbone.blocks.7.attn.proj.bias': {'lr_mult': 0.2373046875,\n",
       "  'decay_mult': 0},\n",
       " 'backbone.blocks.7.norm2.weight': {'lr_mult': 0.2373046875, 'decay_mult': 0},\n",
       " 'backbone.blocks.7.norm2.bias': {'lr_mult': 0.2373046875, 'decay_mult': 0},\n",
       " 'backbone.blocks.7.mlp.layers.0.0.bias': {'lr_mult': 0.2373046875,\n",
       "  'decay_mult': 0},\n",
       " 'backbone.blocks.7.mlp.layers.1.bias': {'lr_mult': 0.2373046875,\n",
       "  'decay_mult': 0},\n",
       " 'backbone.blocks.7.attn.qkv.weight': {'lr_mult': 0.2373046875,\n",
       "  'decay_mult': 1},\n",
       " 'backbone.blocks.7.attn.proj.weight': {'lr_mult': 0.2373046875,\n",
       "  'decay_mult': 1},\n",
       " 'backbone.blocks.7.mlp.layers.0.0.weight': {'lr_mult': 0.2373046875,\n",
       "  'decay_mult': 1},\n",
       " 'backbone.blocks.7.mlp.layers.1.weight': {'lr_mult': 0.2373046875,\n",
       "  'decay_mult': 1},\n",
       " 'backbone.blocks.8.norm1.weight': {'lr_mult': 0.31640625, 'decay_mult': 0},\n",
       " 'backbone.blocks.8.norm1.bias': {'lr_mult': 0.31640625, 'decay_mult': 0},\n",
       " 'backbone.blocks.8.attn.q_bias': {'lr_mult': 0.31640625, 'decay_mult': 0},\n",
       " 'backbone.blocks.8.attn.v_bias': {'lr_mult': 0.31640625, 'decay_mult': 0},\n",
       " 'backbone.blocks.8.attn.proj.bias': {'lr_mult': 0.31640625, 'decay_mult': 0},\n",
       " 'backbone.blocks.8.norm2.weight': {'lr_mult': 0.31640625, 'decay_mult': 0},\n",
       " 'backbone.blocks.8.norm2.bias': {'lr_mult': 0.31640625, 'decay_mult': 0},\n",
       " 'backbone.blocks.8.mlp.layers.0.0.bias': {'lr_mult': 0.31640625,\n",
       "  'decay_mult': 0},\n",
       " 'backbone.blocks.8.mlp.layers.1.bias': {'lr_mult': 0.31640625,\n",
       "  'decay_mult': 0},\n",
       " 'backbone.blocks.8.attn.qkv.weight': {'lr_mult': 0.31640625, 'decay_mult': 1},\n",
       " 'backbone.blocks.8.attn.proj.weight': {'lr_mult': 0.31640625,\n",
       "  'decay_mult': 1},\n",
       " 'backbone.blocks.8.mlp.layers.0.0.weight': {'lr_mult': 0.31640625,\n",
       "  'decay_mult': 1},\n",
       " 'backbone.blocks.8.mlp.layers.1.weight': {'lr_mult': 0.31640625,\n",
       "  'decay_mult': 1},\n",
       " 'backbone.blocks.9.norm1.weight': {'lr_mult': 0.421875, 'decay_mult': 0},\n",
       " 'backbone.blocks.9.norm1.bias': {'lr_mult': 0.421875, 'decay_mult': 0},\n",
       " 'backbone.blocks.9.attn.q_bias': {'lr_mult': 0.421875, 'decay_mult': 0},\n",
       " 'backbone.blocks.9.attn.v_bias': {'lr_mult': 0.421875, 'decay_mult': 0},\n",
       " 'backbone.blocks.9.attn.proj.bias': {'lr_mult': 0.421875, 'decay_mult': 0},\n",
       " 'backbone.blocks.9.norm2.weight': {'lr_mult': 0.421875, 'decay_mult': 0},\n",
       " 'backbone.blocks.9.norm2.bias': {'lr_mult': 0.421875, 'decay_mult': 0},\n",
       " 'backbone.blocks.9.mlp.layers.0.0.bias': {'lr_mult': 0.421875,\n",
       "  'decay_mult': 0},\n",
       " 'backbone.blocks.9.mlp.layers.1.bias': {'lr_mult': 0.421875, 'decay_mult': 0},\n",
       " 'backbone.blocks.9.attn.qkv.weight': {'lr_mult': 0.421875, 'decay_mult': 1},\n",
       " 'backbone.blocks.9.attn.proj.weight': {'lr_mult': 0.421875, 'decay_mult': 1},\n",
       " 'backbone.blocks.9.mlp.layers.0.0.weight': {'lr_mult': 0.421875,\n",
       "  'decay_mult': 1},\n",
       " 'backbone.blocks.9.mlp.layers.1.weight': {'lr_mult': 0.421875,\n",
       "  'decay_mult': 1},\n",
       " 'backbone.blocks.10.norm1.weight': {'lr_mult': 0.5625, 'decay_mult': 0},\n",
       " 'backbone.blocks.10.norm1.bias': {'lr_mult': 0.5625, 'decay_mult': 0},\n",
       " 'backbone.blocks.10.attn.q_bias': {'lr_mult': 0.5625, 'decay_mult': 0},\n",
       " 'backbone.blocks.10.attn.v_bias': {'lr_mult': 0.5625, 'decay_mult': 0},\n",
       " 'backbone.blocks.10.attn.proj.bias': {'lr_mult': 0.5625, 'decay_mult': 0},\n",
       " 'backbone.blocks.10.norm2.weight': {'lr_mult': 0.5625, 'decay_mult': 0},\n",
       " 'backbone.blocks.10.norm2.bias': {'lr_mult': 0.5625, 'decay_mult': 0},\n",
       " 'backbone.blocks.10.mlp.layers.0.0.bias': {'lr_mult': 0.5625,\n",
       "  'decay_mult': 0},\n",
       " 'backbone.blocks.10.mlp.layers.1.bias': {'lr_mult': 0.5625, 'decay_mult': 0},\n",
       " 'backbone.blocks.10.attn.qkv.weight': {'lr_mult': 0.5625, 'decay_mult': 1},\n",
       " 'backbone.blocks.10.attn.proj.weight': {'lr_mult': 0.5625, 'decay_mult': 1},\n",
       " 'backbone.blocks.10.mlp.layers.0.0.weight': {'lr_mult': 0.5625,\n",
       "  'decay_mult': 1},\n",
       " 'backbone.blocks.10.mlp.layers.1.weight': {'lr_mult': 0.5625,\n",
       "  'decay_mult': 1},\n",
       " 'backbone.blocks.11.norm1.weight': {'lr_mult': 0.75, 'decay_mult': 0},\n",
       " 'backbone.blocks.11.norm1.bias': {'lr_mult': 0.75, 'decay_mult': 0},\n",
       " 'backbone.blocks.11.attn.q_bias': {'lr_mult': 0.75, 'decay_mult': 0},\n",
       " 'backbone.blocks.11.attn.v_bias': {'lr_mult': 0.75, 'decay_mult': 0},\n",
       " 'backbone.blocks.11.attn.proj.bias': {'lr_mult': 0.75, 'decay_mult': 0},\n",
       " 'backbone.blocks.11.norm2.weight': {'lr_mult': 0.75, 'decay_mult': 0},\n",
       " 'backbone.blocks.11.norm2.bias': {'lr_mult': 0.75, 'decay_mult': 0},\n",
       " 'backbone.blocks.11.mlp.layers.0.0.bias': {'lr_mult': 0.75, 'decay_mult': 0},\n",
       " 'backbone.blocks.11.mlp.layers.1.bias': {'lr_mult': 0.75, 'decay_mult': 0},\n",
       " 'backbone.blocks.11.attn.qkv.weight': {'lr_mult': 0.75, 'decay_mult': 1},\n",
       " 'backbone.blocks.11.attn.proj.weight': {'lr_mult': 0.75, 'decay_mult': 1},\n",
       " 'backbone.blocks.11.mlp.layers.0.0.weight': {'lr_mult': 0.75,\n",
       "  'decay_mult': 1},\n",
       " 'backbone.blocks.11.mlp.layers.1.weight': {'lr_mult': 0.75, 'decay_mult': 1},\n",
       " 'backbone.fc_norm.weight': {'lr_mult': 1.0, 'decay_mult': 0},\n",
       " 'backbone.fc_norm.bias': {'lr_mult': 1.0, 'decay_mult': 0},\n",
       " 'cls_head.fc_cls.bias': {'lr_mult': 1.0, 'decay_mult': 0},\n",
       " 'cls_head.fc_cls.weight': {'lr_mult': 1.0, 'decay_mult': 1}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the parameter groups to the format used by mmaction\n",
    "\n",
    "custom_keys = {}\n",
    "for _, group in groups.items():\n",
    "    decay_mult = 0 if group[\"weight_decay\"] == 0 else 1\n",
    "    params = group[\"params\"]\n",
    "    lr_mult = group[\"lr_scale\"]\n",
    "    for param in params:\n",
    "        custom_keys[param] = {\"lr_mult\": lr_mult, \"decay_mult\": decay_mult}\n",
    "\n",
    "custom_keys"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "human-fall-detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
